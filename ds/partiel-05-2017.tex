% stephane [DOT] adjemian [AT] univ [DASH] lemans [DOT] fr
\documentclass[10pt,a4paper,notitlepage,twocolumn]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{palatino}
\usepackage{scrtime}
\usepackage[frenchb]{babel}
\usepackage{float}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\exercice}[1]{\textsc{\textbf{Exercice}} #1}
\newcommand{\question}[1]{\textbf{(#1)}}
\setlength{\parindent}{0cm}



\begin{document}


\title{\textsc{Séries temporelles}}
\author{\textsc{Université du Maine (Partiel, L3)}}
\date{}


\maketitle


\exercice{1} Donner l'expression des vraisemblances exacte et
conditionnelle d'un processus MA(1) d'espérance nulle. On notera
$\mathcal Y_T \equiv \{y_1,y_2,\dots,y_T\}$ l'échantillon et on
supposera que les innovations sont normalement distribuées d'espérance
nulle et de variance $\sigma_{\epsilon}^2$. Serait-il possible
d'estimer les paramètres de ce modèle par les MCO ?

\bigskip
\bigskip

\exercice{2} Supposons que $\{y_t,t\in\mathbb Z\}$ soit un ARMA($1,1$) de la forme :

\[
y_t = 1 + \frac{1}{3}y_{t-1} + \varepsilon_t - \frac{2}{3} \varepsilon_{t-1}
\]
avec $\varepsilon_t$ un bruit blanc d'espérance nulle et de variance 1.\newline

\question{1}   Le    processus   est-il   asymptotiquement
stationnaire  au   second  ordre   et  inversible~?   Justifier  votre
réponse.\newline

On suppose maintenant que le processus est stationnaire au second
ordre.\newline

\question{2} Quelles sont les implications de cette hypothèse sur les
moments d'ordre 1 et 2 ? \question{3} Calculer l'espérance (on notera
$\mu$). \question{4} Calculer les autocovariances d'ordre
0 et 1 (on notera $\gamma(0)$ et $\gamma(1)$). \question{5} Calculer
l'autocovariance d'ordre 2 (on notera $\gamma(2)$). \question{6}
Calculer l'autocovariance d'ordre h (on notera $\gamma(h)$) pour tout
$h>2$.  \question{7} Définisser la fonction d'autocorrélation.

\bigskip
\bigskip

\exercice{3} Calculer les moments d'ordre 1 et 2 d'un processus ARMA(1,2) que nous supposerons stationnaire :
\[
y_t = c + \varphi_1 y_{t-1} + \varphi_2 y_{t-2} + \varepsilon_t - \theta_1 \varepsilon_{t-1} - \theta_2 \varepsilon_{t-2}
\]
où $\varepsilon_t$ est un bruit blanc d'espérance nulle et de variance $\sigma^2$.

\exercice{4} Supposons que pour mesurer la composante cyclique d'une
série temporelle nous considérions la variation de la variable,
\emph{i.e.} supposons que la composante cyclique d'une série temporelle $\{y_t\}_{t\in\mathbb Z}$ soit :
\[
y^c_t = \Delta y_t \equiv y_t-y_{t-1}
\]
\question{1} Montrer que la fonction d'autocovariance de la composante cyclique (notée $\gamma_c(h)$) vérifie :
\[
\gamma_c(h) = 2\gamma(h)-\gamma(h-1)-\gamma(h+1)
\]
où $\gamma(h)$ est la fonction d'autocovariance du processus
$\{y_t\}_{t\in\mathbb Z}$.\newline

On suppose que le processus
stochastique $\{y_t\}_{t\in\mathbb Z}$ est un AR(1) :
\[
y_t = \rho y_{t-1} + \varepsilon_t
\]
avec $\rho$ un réel entre -1 et 1 (exclus) et $\varepsilon_t$ un bruit blanc de variance $\sigma_{\varepsilon}^2$.
\question{2} Calculer la fonction d'autocovariance $\gamma_c(h)$ de la
composante cyclique. Montrer que $\gamma_c(h)\leq 0$ pour tout $h$ si
$\rho\in[0,1[$ et que cette fonction d'autocovariance est de signe
alterné sinon.

\end{document}
